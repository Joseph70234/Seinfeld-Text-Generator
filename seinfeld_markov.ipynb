{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory\n",
    "import os\n",
    "os.chdir('C:/Users/theon/OneDrive/Desktop/Giga Projects/seinfeld text gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically a function to break down sequences of words into the markov dictionaries (e.g. (\"the\", \"quick\", \"brown\") : [\"Fox\"])\n",
    "def add_to_model(model, n, seq):            # function for creating n-grams from given sequence; model=n-gram storage bin; n=length of n-grams; seq=thing to create n-grams from\n",
    "    seq = list(seq[:]) + [None]             # create copy of seq WITHOUT overwriting original (hence, list(seq[:]); none is to signify the end of the sequence for model purposes\n",
    "    for i in range(len(seq)-n):             # iterate through seq to the point where there are enough words remaining to form n-gram (hence -n)\n",
    "        gram = tuple(seq[i:i+n])            # create tuple of n consecutive words, starting at position i; use tuples bc of their immutability\n",
    "        next_item = seq[i+n]                # store the next item that appears after the end of the previous n-gram\n",
    "        if gram not in model:               # check if we have already stored this certain n-gram\n",
    "            model[gram] = []                # create dictionary entry for certain gram\n",
    "        model[gram].append(next_item)       # append another \"outcome\" of the n-gram to the n-gram's dictionary entry\n",
    "\n",
    "# basically a function to use the add_to_model to actually have output\n",
    "def markov_model(n, seq):                   # function for \n",
    "    model = {}                              # here, we create an empty dictionary into which we are going to put the n-grams as a string or list.\n",
    "    add_to_model(model, n, seq)             #we call the add_to_model function on the sequence.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def gen_from_model(n, model, start=None, max_gen=100):              # function for generating text\n",
    "    if start is None:                                               # if we do not specify place to start, start from random sequence\n",
    "        start = random.choice(list(model.keys()))                   # the keys (\"\".keys\") are the sequences in the model (\"model\") we created earlier.\n",
    "    output = list(start)                                            # create first element of output\n",
    "    for i in range(max_gen):                                        # iterate through number of generated words we want\n",
    "        start = tuple(output[-n:])                                  # we format that ngram (\"output[-n:]\") as a tuple; output[-n:] grabs the last n items from the output\n",
    "        next_item = random.choice(model[start])                     # check the dictionary entry corresponding to the \"start\" n-gram, and choose a random follow-up word\n",
    "        if next_item is None:                                       \n",
    "            break                                                   # exit the for-loop\n",
    "        else:\n",
    "            output.append(next_item)                                # grab the next n-gram to continue the process\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set n-grams and starting point\n",
    "n_grams = 3\n",
    "starting_pos = None\n",
    "\n",
    "# generate markov chain\n",
    "sein_word_model = markov_model(n_grams, open(\"standardized_seinfeld_script.txt\").read().split())\n",
    "generated_words = gen_from_model(n_grams, sein_word_model, starting_pos, max_gen=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dir again\n",
    "os.chdir('C:/Users/theon/OneDrive/Desktop/Giga Projects/seinfeld text gen/sein_markov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write generated text to file\n",
    "with open(\"generated_sein.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for word in generated_words:\n",
    "        if any(char in word for char in [':', '[', '(']):\n",
    "            word = \"\\n \" + word\n",
    "        file.write(word+' ')\n",
    "\n",
    "with open(\"generated_sein.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines[0] = f\"GENERATED SEINFELD SCRIPT: {n_grams}-grams starting from {starting_pos} \\n\"\n",
    "\n",
    "with open(\"generated_sein.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.writelines(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
